name: ProcessTrainingHistory
description: >
  Converts training history (per-epoch arrays) into row-wise
  records suitable for DB ingestion.

inputs:
  - name: training_history_json
    type: String
    description: JSON with per-epoch metric arrays

  - name: mapping_json
    type: String
    description: Metric mapping configuration

  - name: tenant_id
    type: String

  - name: execution_id
    type: Integer

  - name: projectId
    type: String

  - name: model_id
      type: String

outputs:
  - name: processed_history_json
    type: String
    description: Row-wise epoch records

implementation:
  container:
    image: python:3.9-slim
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os

        parser = argparse.ArgumentParser()
        parser.add_argument("--training_history_json", required=True)
        parser.add_argument("--mapping_json", required=True)
        parser.add_argument("--tenant_id", required=True)
        parser.add_argument("--execution_id", required=True)
        parser.add_argument("--projectId", required=True)
        parser.add_argument("--model_id", required=True)
        parser.add_argument("--processed_history_json", required=True)
        args = parser.parse_args()

        # --------------------------------------------------
        # Load inputs
        # --------------------------------------------------
        history = json.load(open(args.training_history_json))
        mapping = json.loads(args.mapping_json)

        # Resolve metric arrays
        loss_key = mapping.get("loss")
        acc_key = mapping.get("accuracy")

        losses = history.get(loss_key, [])
        accuracies = history.get(acc_key, [])

        if not losses or not accuracies:
            raise ValueError("Loss or accuracy arrays missing")

        if len(losses) != len(accuracies):
            raise ValueError("Loss and accuracy lengths do not match")

        # --------------------------------------------------
        # Expand into rows
        # --------------------------------------------------
        rows = []

        for epoch in range(len(losses)):
            rows.append({
                "tenant_id": args.tenant_id,
                "projectId": args.projectId,
                "execution_id": args.execution_id,
                "model_id": args.model_id
                "epoch": int(epoch),
                "loss": float(losses[epoch]),
                "accuracy": float(accuracies[epoch])
            })

        # --------------------------------------------------
        # Save output
        # --------------------------------------------------
        os.makedirs(os.path.dirname(args.processed_history_json), exist_ok=True)
        with open(args.processed_history_json, "w") as f:
            json.dump(rows, f, indent=2)

        print(f"Generated {len(rows)} epoch records")

    args:
      - --training_history_json
      - {inputPath: training_history_json}
      - --mapping_json
      - {inputValue: mapping_json}
      - --tenant_id
      - {inputValue: tenant_id}
      - --execution_id
      - {inputValue: execution_id}
      - --projectId
      - {inputValue: projectId}
      - --model_id
      - {inputValue: model_id}
      - --processed_history_json
      - {outputPath: processed_history_json}

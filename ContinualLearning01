name: ContinualLearningCNN
description: |
  Replay-based continual learning for CNN models.
  - Loads previous model checkpoint (.pt)
  - Loads optional replay buffer (first run works without it)
  - Adds new data into replay memory
  - Trains CNN using combined memory
  - Outputs updated model + replay buffer

inputs:
  - name: processed_data_pickle
    type: Dataset

  - name: previous_model
    type: Model

  - name: previous_replay_buffer
    type: Dataset
    optional: true

  - name: config
    type: String

outputs:
  - name: updated_model
    type: Model

  - name: updated_replay_buffer
    type: Dataset

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        python3 -m pip install --quiet --upgrade pip setuptools wheel
        python3 -m pip install --quiet "torch==1.13.1+cpu" "torchvision==0.14.1+cpu" -f https://download.pytorch.org/whl/cpu/torch_stable.html
        python3 -m pip install --quiet pandas numpy scikit-learn
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import os, json, pickle, torch, random

        # -----------------------------
        # Parse arguments
        # -----------------------------
        import argparse
        parser = argparse.ArgumentParser()
        parser.add_argument("--processed_data_pickle", required=True)
        parser.add_argument("--previous_model", required=False)
        parser.add_argument("--previous_replay_buffer", required=False)
        parser.add_argument("--config", required=True)
        parser.add_argument("--updated_model", required=True)
        parser.add_argument("--updated_replay_buffer", required=True)
        args = parser.parse_args()

        cfg = json.loads(args.config)

        # -----------------------------
        # Load new dataset
        # -----------------------------
        with open(args.processed_data_pickle, "rb") as f:
            new_data = pickle.load(f)

        # -----------------------------
        # Load replay buffer
        # -----------------------------
        if args.previous_replay_buffer and os.path.exists(args.previous_replay_buffer):
            with open(args.previous_replay_buffer, "rb") as f:
                replay_buffer = pickle.load(f)
        else:
            replay_buffer = []

        # -----------------------------
        # Load or create the model
        # -----------------------------
        if args.previous_model and os.path.exists(args.previous_model):
            model = torch.load(args.previous_model, map_location="cpu")
        else:
            # Define a default CNN architecture
            import torch.nn as nn
            class SimpleCNN(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.conv = nn.Sequential(
                        nn.Conv2d(1, 16, 3, padding=1),
                        nn.ReLU(),
                        nn.MaxPool2d(2)
                    )
                    self.fc = nn.Sequential(
                        nn.Flatten(),
                        nn.Linear(16 * 14 * 14, 10)
                    )
                def forward(self, x):
                    return self.fc(self.conv(x))

            model = SimpleCNN()

        # -----------------------------
        # Update replay memory
        # -----------------------------
        memory_limit = cfg.get("memory_size", 2000)

        replay_buffer.extend(new_data)
        random.shuffle(replay_buffer)
        replay_buffer = replay_buffer[:memory_limit]

        # Convert replay to tensors
        X = torch.stack([torch.tensor(d["image"]) for d in replay_buffer]).float()
        y = torch.tensor([d["label"] for d in replay_buffer]).long()

        dataset = torch.utils.data.TensorDataset(X, y)
        loader = torch.utils.data.DataLoader(dataset, batch_size=cfg.get("batch_size", 32), shuffle=True)

        # -----------------------------
        # Training loop
        # -----------------------------
        model.train()
        optimizer = torch.optim.Adam(model.parameters(), lr=cfg.get("lr", 0.001))
        loss_fn = torch.nn.CrossEntropyLoss()

        for epoch in range(cfg.get("epochs", 5)):
            for bx, by in loader:
                optimizer.zero_grad()
                pred = model(bx)
                loss = loss_fn(pred, by)
                loss.backward()
                optimizer.step()

        # -----------------------------
        # Save outputs
        # -----------------------------
        torch.save(model, args.updated_model)

        with open(args.updated_replay_buffer, "wb") as f:
            pickle.dump(replay_buffer, f)

        print("Continual learning step completed successfully.")

    args:
      - --processed_data_pickle
      - {inputPath: processed_data_pickle}

      - --previous_model
      - {inputPath: previous_model}

      - --previous_replay_buffer
      - {inputPath: previous_replay_buffer}

      - --config
      - {inputValue: config}

      - --updated_model
      - {outputPath: updated_model}

      - --updated_replay_buffer
      - {outputPath: updated_replay_buffer}

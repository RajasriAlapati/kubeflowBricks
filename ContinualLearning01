name: ContinualLearningCNN
description: Replay-based continual learning for CNN models.

inputs:
  - name: processed_data_pickle
    type: Dataset

  - name: previous_model
    type: Model
    description: "Optional previous model checkpoint"
    optional: true

  - name: previous_replay_buffer
    type: String
    description: "Optional previous replay buffer pickle"
    optional: true

  - name: config_str
    type: String
    description: "Training + replay configuration JSON string"

outputs:
  - name: updated_model
    type: Model
  - name: updated_replay_buffer
    type: Dataset
  - name: training_report
    type: String

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        set -e
        # Install common ML packages (optional; remove or pin as needed)
        python3 -m pip install --quiet --upgrade pip setuptools wheel
        python3 -m pip install --quiet "numpy<2,>=1.22" "pillow" "torch" "torchvision==0.17.0"
        # Hand over control to the next command in the list
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import os, json, torch, pickle, argparse, random
        import torch.nn as nn
        import torch.optim as optim

        parser = argparse.ArgumentParser()
        parser.add_argument("--processed_data_pickle")
        parser.add_argument("--previous_model", required=False)
        parser.add_argument("--previous_replay_buffer", required=False)
        parser.add_argument("--config_str")
        parser.add_argument("--updated_model")
        parser.add_argument("--updated_replay_buffer")
        parser.add_argument("--training_report")
        args = parser.parse_args()

        # -------------------------------------------------------
        # Load config
        # -------------------------------------------------------
        cfg = json.loads(args.config_str)

        replay_size = cfg["training"].get("replay_buffer_size", 500)
        batch_size = cfg["training"].get("batch_size", 32)
        lr = cfg["training"]["optimizer"].get("learning_rate", 0.001)
        epochs = cfg["training"].get("epochs", 3)
        device = "cuda" if torch.cuda.is_available() else "cpu"

        # -------------------------------------------------------
        # Load new processed data
        # -------------------------------------------------------
        with open(args.processed_data_pickle, "rb") as f:
            processed = pickle.load(f)

        train_loader = processed.train_loader
        num_classes = processed.num_classes

        # -------------------------------------------------------
        # Build Model
        # -------------------------------------------------------
        class SimpleCNN(nn.Module):
            def __init__(self, num_classes):
                super().__init__()
                self.features = nn.Sequential(
                    nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
                    nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)
                )
                self.classifier = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(64*56*56, 128),
                    nn.ReLU(),
                    nn.Linear(128, num_classes)
                )

            def forward(self, x):
                x = self.features(x)
                return self.classifier(x)

        model = SimpleCNN(num_classes).to(device)

        # -------------------------------------------------------
        # Load previous model (optional)
        # -------------------------------------------------------
        if args.previous_model and os.path.exists(args.previous_model):
            print("Loading previous model checkpoint")
            model.load_state_dict(torch.load(args.previous_model, map_location=device))
        else:
            print("No previous model provided — training from scratch")

        # -------------------------------------------------------
        # Load previous replay buffer (optional)
        # -------------------------------------------------------
        replay_buffer = []

        if args.previous_replay_buffer and os.path.exists(args.previous_replay_buffer):
            print("Loading previous replay buffer")
            with open(args.previous_replay_buffer, "rb") as f:
                replay_buffer = pickle.load(f)
        else:
            print("No previous replay buffer provided")

        optimizer = optim.Adam(model.parameters(), lr=lr)
        loss_fn = nn.CrossEntropyLoss()

        # -------------------------------------------------------
        # Convert replay buffer → DataLoader
        # -------------------------------------------------------
        def build_replay_loader(buffer):
            if len(buffer) == 0:
                return None

            tensor_x = torch.stack([item[0] for item in buffer])
            tensor_y = torch.tensor([item[1] for item in buffer])

            ds = torch.utils.data.TensorDataset(tensor_x, tensor_y)
            return torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True)

        replay_loader = build_replay_loader(replay_buffer)

        # -------------------------------------------------------
        # Training loop with replay
        # -------------------------------------------------------
        def sample_batch(loader):
            for batch in loader:
                yield batch

        report = {"epochs": epochs, "loss_per_epoch": []}

        for ep in range(epochs):
            model.train()
            total_loss = 0

            # Mix replay + new data
            loaders = []
            if replay_loader:
                loaders.append(sample_batch(replay_loader))
            loaders.append(sample_batch(train_loader))

            for loader in loaders:
                for x, y in loader:
                    x, y = x.to(device), y.to(device)

                    optimizer.zero_grad()
                    out = model(x)
                    loss = loss_fn(out, y)
                    loss.backward()
                    optimizer.step()

                    total_loss += loss.item()

            avg_loss = total_loss
            report["loss_per_epoch"].append(avg_loss)
            print(f"Epoch {ep+1}/{epochs} - Loss={avg_loss}")

        # -------------------------------------------------------
        # Update replay buffer
        # -------------------------------------------------------
        # Extract random samples from new data
        new_buffer_items = []

        for x, y in train_loader:
            for i in range(len(x)):
                new_buffer_items.append((x[i].cpu(), int(y[i])))

        # Merge old + new
        combined = replay_buffer + new_buffer_items

        # Keep replay size fixed
        random.shuffle(combined)
        combined = combined[:replay_size]

        # -------------------------------------------------------
        # Save updated replay buffer
        # -------------------------------------------------------
        with open(args.updated_replay_buffer, "wb") as f:
            pickle.dump(combined, f)

        # -------------------------------------------------------
        # Save updated model
        # -------------------------------------------------------
        torch.save(model.state_dict(), args.updated_model)

        # -------------------------------------------------------
        # Save training report
        # -------------------------------------------------------
        with open(args.training_report, "w") as f:
            json.dump(report, f, indent=2)

        print("Continual Learning update complete!")
    args:
      - --processed_data_pickle
      - {inputPath: processed_data_pickle}
      - --previous_model
      - {inputPath: previous_model}
      - --previous_replay_buffer
      - {inputPath: previous_replay_buffer}
      - --config_str
      - {inputValue: config_str}
      - --updated_model
      - {outputPath: updated_model}
      - --updated_replay_buffer
      - {outputPath: updated_replay_buffer}
      - --training_report
      - {outputPath: training_report}

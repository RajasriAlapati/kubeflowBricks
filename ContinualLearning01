name: ContinualLearningCNN
description: |
  Perform replay-based continual learning for a CNN model.
  - Loads previous model checkpoint (.pt)
  - Loads optional replay buffer (first run works without it)
  - Merges new data with replay memory
  - Re-trains CNN
  - Outputs updated model checkpoint + updated replay buffer

inputs:
  - name: processed_data_pickle
    type: Dataset
    description: "Pickled dataset of processed UI components"

  - name: previous_model
    type: Model
    description: "Previous CNN checkpoint (.pt). If not provided, trains from scratch"

  - name: previous_replay_buffer
    type: Dataset
    description: "Replay buffer pickle. Optional in first run"

  - name: config
    type: String
    description: "JSON string: {\"epochs\": 5, \"batch_size\": 32, \"lr\": 0.001, \"memory_size\": 2000}"

outputs:
  - name: updated_model
    type: Model

  - name: updated_replay_buffer
    type: Dataset

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        python3 -m pip install --quiet --upgrade pip setuptools wheel
        python3 -m pip install --quiet "torch==1.13.1+cpu" "torchvision==0.14.1+cpu" -f https://download.pytorch.org/whl/cpu/torch_stable.html
        python3 -m pip install --quiet pandas numpy scikit-learn
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import os, json, pickle, torch, random
        import numpy as np

        # -----------------------------
        # Load Inputs
        # -----------------------------
        cfg = json.loads(config)

        # Load new dataset
        with open(processed_data_pickle, "rb") as f:
            new_data = pickle.load(f)

        # Load previous replay buffer
        if previous_replay_buffer and os.path.exists(previous_replay_buffer):
            with open(previous_replay_buffer, "rb") as f:
                replay_buffer = pickle.load(f)
        else:
            replay_buffer = []

        # Load previous model
        if previous_model and os.path.exists(previous_model):
            model = torch.load(previous_model, map_location="cpu")
        else:
            # ---- CREATE NEW CNN HERE ----
            import torch.nn as nn
            class SimpleCNN(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.conv = nn.Sequential(
                        nn.Conv2d(1, 16, 3, padding=1),
                        nn.ReLU(),
                        nn.MaxPool2d(2)
                    )
                    self.fc = nn.Sequential(
                        nn.Flatten(),
                        nn.Linear(16 * 14 * 14, 10)
                    )
                def forward(self, x):
                    return self.fc(self.conv(x))
            model = SimpleCNN()

        # -----------------------------
        # Prepare Replay Memory
        # -----------------------------
        memory_limit = cfg.get("memory_size", 2000)

        # Add new samples
        replay_buffer.extend(new_data)

        # Shuffle once
        random.shuffle(replay_buffer)

        # Trim to memory limit
        replay_buffer = replay_buffer[:memory_limit]

        # -----------------------------
        # Convert replay to tensors
        # -----------------------------
        X = torch.stack([torch.tensor(d["image"]) for d in replay_buffer]).float()
        y = torch.tensor([d["label"] for d in replay_buffer]).long()

        dataset = torch.utils.data.TensorDataset(X, y)
        loader = torch.utils.data.DataLoader(dataset, batch_size=cfg.get("batch_size", 32), shuffle=True)

        # -----------------------------
        # Training Loop
        # -----------------------------
        model.train()
        optimizer = torch.optim.Adam(model.parameters(), lr=cfg.get("lr", 0.001))
        loss_fn = torch.nn.CrossEntropyLoss()

        for epoch in range(cfg.get("epochs", 5)):
            for batch_x, batch_y in loader:
                optimizer.zero_grad()
                pred = model(batch_x)
                loss = loss_fn(pred, batch_y)
                loss.backward()
                optimizer.step()

        # -----------------------------
        # Save outputs
        # -----------------------------
        torch.save(model, updated_model)

        with open(updated_replay_buffer, "wb") as f:
            pickle.dump(replay_buffer, f)

        print("Training complete. Model + replay buffer saved.")

  args:
        - --processed_data_pickle
        - {inputPath: processed_data_pickle}
  
        - --previous_model
        - {inputPath: previous_model}
  
        - --previous_replay_buffer
        - {inputPath: previous_replay_buffer}
  
        - --config
        - {inputValue: config}
  
        - --updated_model
        - {outputPath: updated_model}
  
        - --updated_replay_buffer
        - {outputPath: updated_replay_buffer}

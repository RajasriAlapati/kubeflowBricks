name: forward
description: Trains a CNN model (ResNet) using Backpropagation, CAFO, or Forward-Forward based on configuration.

inputs:
  - name: data_path
    type: Dataset
  - name: config
    type: String

outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v34
    command:
      - sh
      - -c
      - |
        python3 -m pip install --quiet --upgrade pip setuptools wheel
        python3 -m pip install --quiet "torchvision==0.17.0"
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse, pickle, os, json, sys, time, io, traceback
        from torch.utils.data import TensorDataset, DataLoader
        import nesy_factory.CNNs.ffresnet as ffresnet

        # Define the LabeledDataset and CustomJSONDataset classes for unpickling
        class LabeledDataset:
            def __init__(self, *args, **kwargs):
                obj = None
                if "dataset" in kwargs:
                    obj = kwargs["dataset"]
                elif len(args) == 1:
                    obj = args[0]
                else:
                    obj = kwargs

                self.dataset = getattr(obj, "dataset", None) or \
                               getattr(obj, "data", None) or \
                               getattr(obj, "samples", None) or \
                               obj

            def __len__(self):
                try:
                    return len(self.dataset)
                except:
                    return 100

            def __getitem__(self, idx):
                try:
                    item = self.dataset[idx]
                    if isinstance(item, tuple) and len(item) == 2:
                        return item
                    if isinstance(item, dict):
                        return item.get("image_data"), item.get("label", 0)
                except:
                    pass
                return torch.randn(3,224,224), 0
        
        class CustomJSONDataset(LabeledDataset):
            def __init__(self, *args, **kwargs):
                super().__init__(*args, **kwargs)

        class DataWrapper:
            def __init__(self, d=None):
                if d:
                    self.__dict__.update(d)

        # Safe unpickler to load datasets safely
        class SafeUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                if name == "LabeledDataset":
                    return LabeledDataset
                if name == "CustomJSONDataset":
                    return CustomJSONDataset
                if name == "DataWrapper":
                    return DataWrapper
                return super().find_class(module, name)

        # Dataset loading helper
        def extract_tensors(loader):
            X, y = [], []
            for bx, by in loader:
                X.append(bx)
                y.append(by)
            return torch.cat(X), torch.cat(y)

        # Patched ResNet with backpropagation method
        class PatchedResNet(ffresnet.ResNet):
            def __init__(self, config):
                super().__init__(config)
            
            def train_backpropagation(self, X_train, y_train, X_val=None, y_val=None, verbose=True):
                '''Standard backpropagation training method.'''
                # Get training config
                optimizer = torch.optim.Adam(self.parameters(), lr=self.config.get('learning_rate', 0.001))
                criterion = self.criterion
                num_epochs = self.config.get('epochs', 50)
                batch_size = self.config.get('batch_size', 32)
                
                # Move data to device
                device = next(self.parameters()).device
                X_train, y_train = X_train.to(device), y_train.to(device)
                if X_val is not None:
                    X_val, y_val = X_val.to(device), y_val.to(device)

                # Create dataloaders
                train_dataset = TensorDataset(X_train, y_train)
                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

                # Training loop
                self.train()
                train_losses = []
                val_losses = []
                
                for epoch in range(num_epochs):
                    epoch_loss = 0.0
                    for batch_X, batch_y in train_loader:
                        optimizer.zero_grad()
                        outputs = self(batch_X)
                        loss = criterion(outputs, batch_y)
                        loss.backward()
                        optimizer.step()
                        epoch_loss += loss.item()
                    
                    avg_train_loss = epoch_loss / len(train_loader)
                    train_losses.append(avg_train_loss)

                    # Validation
                    if X_val is not None and y_val is not None:
                        self.eval()
                        with torch.no_grad():
                            val_outputs = self(X_val)
                            val_loss = criterion(val_outputs, y_val)
                            val_losses.append(val_loss.item())
                        self.train()

                    if verbose and epoch % 10 == 0:
                        val_info = f", Val Loss: {val_losses[-1]:.4f}" if val_losses else ""
                        print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}{val_info}")

                return {
                    "train_losses": train_losses,
                    "val_losses": val_losses if val_losses else None
                }

        ResNet = PatchedResNet

        # Parse arguments
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--config", required=True)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        args = parser.parse_args()

        # Load dataset
        print("Loading dataset...")
        with open(args.data_path, "rb") as f:
            processed = SafeUnpickler(io.BytesIO(f.read())).load()

        # Extract data
        train_loader = processed.train_loader
        test_loader = getattr(processed, "test_loader", None)
        num_classes = processed.num_classes
        image_size = processed.image_size

        X_train, y_train = extract_tensors(train_loader)
        X_val, y_val = (extract_tensors(test_loader) if test_loader else (None, None))

        # Load and parse config
        print("Loading configuration...")
        cfg = json.loads(args.config)
        model_cfg = cfg.get("model", {})
        training_cfg = cfg.get("training", {})
        
        # Extract training mode flags from config (NO DEFAULTS)
        use_cafo = model_cfg.get("use_cafo")
        use_forward_forward = model_cfg.get("use_forward_forward")
        
        # Validate: can't use both CAFO and FF
        if use_cafo and use_forward_forward:
            raise ValueError("Cannot use both CAFO and Forward-Forward. Set one to false in config.")
        
        # Determine training mode
        if use_cafo:
            training_mode = "CAFO"
        elif use_forward_forward:
            training_mode = "Forward-Forward"
        else:
            training_mode = "Backpropagation"
        
        print(f"Training mode: {training_mode}")

        # Build ResNet config from input config
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        resnet_cfg = {
            # Basic model params
            "input_channels": model_cfg.get("input_channels", 3),
            "output_dim": num_classes,
            "variant": model_cfg.get("variant", "resnet50"),
            "pretrained": model_cfg.get("pretrained", False),
            "dropout": model_cfg.get("dropout", 0.0),
            "device": str(device),
            
            # Training mode flags
            "use_cafo": use_cafo if use_cafo is not None else False,
            "use_forward_forward": use_forward_forward if use_forward_forward is not None else False,
            
            # Training params (for backpropagation)
            "learning_rate": training_cfg.get("optimizer", {}).get("learning_rate", 0.001),
            "batch_size": training_cfg.get("batch_size", 32),
            "epochs": 50,  # Default for backpropagation
        }
        
        # Add CAFO-specific params if CAFO mode
        if use_cafo:
            resnet_cfg.update({
                "cafo_blocks": model_cfg.get("cafo_blocks", 4),
                "epochs_per_block": model_cfg.get("epochs_per_block", 50),
                "block_lr": model_cfg.get("block_lr", 0.001),
            })
        
        # Add Forward-Forward params if FF mode
        if use_forward_forward:
            ff_cfg = model_cfg.get("forward_forward", {})
            resnet_cfg.update({
                "ff_blocks": ff_cfg.get("ff_blocks", 4),
                "ff_epochs_per_block": ff_cfg.get("ff_epochs_per_block", 50),
                "ff_lr": ff_cfg.get("ff_lr", 0.01),
                "ff_threshold": ff_cfg.get("threshold", 2.0),
                "ff_goodness_dim": ff_cfg.get("ff_goodness_dim", 128),
            })

        # Create model
        print(f"Creating {resnet_cfg['variant']} model...")
        net = ResNet(resnet_cfg).to(device)
        print(f"Model created with {sum(p.numel() for p in net.parameters())} parameters")

        # Train based on mode
        print(f"Starting {training_mode} training...")
        
        if use_cafo:
            results = net.train_cafo(
                X_train.to(device),
                y_train.to(device),
                X_val.to(device) if X_val is not None else None,
                y_val.to(device) if y_val is not None else None,
                verbose=True
            )
            model_trained_flag = {"cafo_trained": True}
            
        elif use_forward_forward:
            results = net.train_forward_forward(
                X_train.to(device),
                y_train.to(device),
                X_val.to(device) if X_val is not None else None,
                y_val.to(device) if y_val is not None else None,
                verbose=True
            )
            model_trained_flag = {"ff_trained": True}
            
        else:
            results = net.train_backpropagation(
                X_train.to(device),
                y_train.to(device),
                X_val.to(device) if X_val is not None else None,
                y_val.to(device) if y_val is not None else None,
                verbose=True
            )
            model_trained_flag = {"backprop_trained": True}

        # Save model & history
        print("Saving model and training history...")
        os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
        os.makedirs(os.path.dirname(args.training_history), exist_ok=True)

        # Save model state
        save_dict = {
            "model_state_dict": net.state_dict(),
            "config": resnet_cfg,
            "training_mode": training_mode
        }
        save_dict.update(model_trained_flag)
        torch.save(save_dict, args.trained_model)

        # Save training history
        history = {
            "training_mode": training_mode,
            "results": results,
            "config": resnet_cfg
        }
        with open(args.training_history, "w") as f:
            json.dump(history, f, indent=2)

        print(f"✓ {training_mode} training completed successfully!")
        print(f"✓ Model saved to: {args.trained_model}")
        print(f"✓ History saved to: {args.training_history}")
        
    args:
      - --data_path
      - {inputPath: data_path}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}

name: forward
description: Trains a Forward-Forward CNN model using processed UI components dataset and configuration.

inputs:
  - name: data_path
    type: Dataset
  - name: config
    type: String

outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v30
    command:
      - python3
      - -u
      - -c
      - |
        import torch
        import argparse, pickle, os, json, sys, time, io, traceback
        from torch.utils.data import TensorDataset, DataLoader
        import nesy_factory.CNNs.ffresnet as ffresnet

        # Define the LabeledDataset and CustomJSONDataset classes for unpickling
        class LabeledDataset:
            def __init__(self, *args, **kwargs):
                obj = None
                if "dataset" in kwargs:
                    obj = kwargs["dataset"]
                elif len(args) == 1:
                    obj = args[0]
                else:
                    obj = kwargs

                self.dataset = getattr(obj, "dataset", None) or \
                               getattr(obj, "data", None) or \
                               getattr(obj, "samples", None) or \
                               obj

            def __len__(self):
                try:
                    return len(self.dataset)
                except:
                    return 100

            def __getitem__(self, idx):
                try:
                    item = self.dataset[idx]
                    if isinstance(item, tuple) and len(item) == 2:
                        return item
                    if isinstance(item, dict):
                        return item.get("image_data"), item.get("label", 0)
                except:
                    pass
                return torch.randn(3,224,224), 0
        
        # Define the CustomJSONDataset class
        class CustomJSONDataset(LabeledDataset):
            def __init__(self, *args, **kwargs):
                super().__init__(*args, **kwargs)
                # Add any specific customization you need for your dataset here

        # Safe unpickler to load datasets safely
        class SafeUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                if name == "LabeledDataset":
                    return LabeledDataset
                if name == "CustomJSONDataset":
                    return CustomJSONDataset  # Handle CustomJSONDataset
                if name == "DataWrapper":
                    return DataWrapper
                return super().find_class(module, name)

        # Dataset loading method
        def extract_tensors(loader):
            X, y = [], []
            for bx, by in loader:
                X.append(bx)
                y.append(by)
            return torch.cat(X), torch.cat(y)

        # Patch imports and initialize base CNN class
        class PatchedResNet(ffresnet.ResNet):
            def __init__(self, config):
                setattr(self, "dropout", config.get("dropout", 0.0))
                super().__init__(config)

        ResNet = PatchedResNet

        # Parse arguments
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--config", required=True)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--training_history", required=True)
        args = parser.parse_args()

        # Load dataset
        with open(args.data_path, "rb") as f:
            processed = SafeUnpickler(io.BytesIO(f.read())).load()

        # Extract data tensors
        train_loader = processed.train_loader
        test_loader  = getattr(processed, "test_loader", None)
        num_classes  = processed.num_classes
        image_size   = processed.image_size

        # Extract tensors
        X_train, y_train = extract_tensors(train_loader)
        X_val, y_val = (extract_tensors(test_loader) if test_loader else (None, None))

        # Load config
        cfg = json.loads(args.config)
        ff_cfg = cfg.get("model", {}).get("forward_forward", {})
        dropout = ff_cfg.get("dropout", 0.0)

        # Construct ResNet model based on the config
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        resnet_cfg = {
            "input_channels": 3,
            "output_dim": num_classes,
            "variant": ff_cfg.get("variant", "resnet50"),
            "use_forward_forward": ff_cfg.get("use_forward_forward", False),
            "use_cafo": ff_cfg.get("use_cafo", False),
            "ff_lr": ff_cfg.get("ff_lr", 0.0001),
            "ff_epochs_per_block": ff_cfg.get("ff_epochs_per_block", 50),
            "ff_threshold": ff_cfg.get("threshold", 2.0),
            "ff_blocks": ff_cfg.get("ff_blocks", 4),
            "dropout": dropout,
            "device": str(device),
        }

        net = ResNet(resnet_cfg).to(device)

        # Check which method to use for training
        if ff_cfg.get("use_cafo", False):
            print("Training with CAFO...")
            results = net.train_cafo(
                X_train.to(device),
                y_train.to(device),
                X_val.to(device) if X_val is not None else None,
                y_val.to(device) if y_val is not None else None,
                verbose=True
            )
        elif ff_cfg.get("use_forward_forward", False):
            print("Training with Forward-Forward...")
            results = net.train_forward_forward(
                X_train.to(device),
                y_train.to(device),
                X_val.to(device) if X_val is not None else None,
                y_val.to(device) if y_val is not None else None,
                verbose=True
            )
        else:
            print("Training with Backpropagation...")
            results = net.train_backpropagation(
                X_train.to(device),
                y_train.to(device),
                X_val.to(device) if X_val is not None else None,
                y_val.to(device) if y_val is not None else None,
                verbose=True
            )

        # Save model & history
        os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
        os.makedirs(os.path.dirname(args.training_history), exist_ok=True)

        torch.save({"model_state_dict": net.state_dict(), "ff_trained": True}, args.trained_model)
        with open(args.training_history, "w") as f:
            json.dump({"ff_results": results}, f, indent=2)

        print("Training completed successfully.")
    args:
      - --data_path
      - {inputPath: data_path}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --training_history
      - {outputPath: training_history}
